#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å›¾çŠ¶æ€ç®¡ç†çš„ MindSearchAgent
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from agents.mindsearch_agent import MindSearchAgent, LLMProvider
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    from langchain_rebuild.agents.mindsearch_agent import MindSearchAgent, LLMProvider


def print_callback(data):
    """æ‰“å°å›è°ƒå‡½æ•°"""
    msg_type = data.get('type', 'unknown')
    msg_data = data.get('data', {})
    
    if msg_type == 'status':
        print(f"ğŸ“Š çŠ¶æ€: {msg_data.get('message', '')}")
    elif msg_type == 'graph_created':
        graph_data = msg_data
        print(f"ğŸ”— å›¾å·²åˆ›å»º: {len(graph_data.get('nodes', {}))} ä¸ªèŠ‚ç‚¹, {len(graph_data.get('edges', {}))} æ¡è¾¹")
    elif msg_type == 'sub_query_start':
        print(f"ğŸ” å¼€å§‹å­æŸ¥è¯¢: {msg_data.get('query', '')} (èŠ‚ç‚¹: {msg_data.get('node_id', '')})")
    elif msg_type == 'sub_query_complete':
        print(f"âœ… å­æŸ¥è¯¢å®Œæˆ: {msg_data.get('query', '')}")
    elif msg_type == 'node_updated':
        print(f"ğŸ”„ èŠ‚ç‚¹æ›´æ–°: {msg_data.get('node_id', '')} -> {msg_data.get('status', '')}")
    elif msg_type == 'graph_complete':
        print(f"ğŸ¯ å›¾æ‰§è¡Œå®Œæˆ")
    elif msg_type == 'answer_chunk':
        # æµå¼ç­”æ¡ˆï¼Œåªæ˜¾ç¤ºè¿›åº¦
        content = msg_data.get('content', '')
        print(f"\rğŸ’¬ ç”Ÿæˆç­”æ¡ˆä¸­... ({len(content)} å­—ç¬¦)", end='', flush=True)
    elif msg_type == 'complete':
        print("\nğŸ‰ æœç´¢å®Œæˆ!")
    elif msg_type == 'error':
        print(f"âŒ é”™è¯¯: {msg_data.get('error', '')}")


async def test_graph_search():
    """æµ‹è¯•å›¾æœç´¢åŠŸèƒ½"""
    print("=== æµ‹è¯•å›¾çŠ¶æ€ç®¡ç†çš„ MindSearchAgent ===")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = MindSearchAgent(
        llm_provider=LLMProvider.SILICONFLOW,
        max_search_steps=3,
        max_results_per_search=5
    )
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿå®ƒæœ‰å“ªäº›åº”ç”¨é¢†åŸŸï¼Ÿ"
    print(f"\nğŸ¤” æŸ¥è¯¢: {query}")
    print("-" * 50)
    
    try:
        # æ‰§è¡Œæœç´¢
        session = await agent.asearch(query, callback_func=print_callback)
        
        print("\n" + "=" * 50)
        print("ğŸ“‹ æœç´¢ç»“æœæ‘˜è¦:")
        print(f"ä¼šè¯ID: {session.session_id}")
        print(f"åŸå§‹æŸ¥è¯¢: {session.original_query}")
        print(f"æœç´¢æ­¥éª¤æ•°: {len(session.search_steps)}")
        print(f"æ€»å¼•ç”¨æ•°: {len(session.total_references)}")
        
        # æ˜¾ç¤ºæŸ¥è¯¢è®¡åˆ’
        if session.query_plan:
            print(f"\nğŸ“ æŸ¥è¯¢è®¡åˆ’:")
            for i, sub_query in enumerate(session.query_plan.sub_queries, 1):
                print(f"  {i}. {sub_query.query}")
                if sub_query.dependencies:
                    print(f"     ä¾èµ–: {sub_query.dependencies}")
        
        # æ˜¾ç¤ºæœç´¢æ­¥éª¤
        print(f"\nğŸ” æœç´¢æ­¥éª¤:")
        for i, step in enumerate(session.search_steps, 1):
            print(f"  {i}. {step.query}")
            print(f"     ç»“æœæ•°: {len(step.search_results)}")
            print(f"     å¼•ç”¨æ•°: {len(step.references)}")
            print(f"     åˆ†æ: {step.analysis[:100]}..." if len(step.analysis) > 100 else f"     åˆ†æ: {step.analysis}")
        
        # æ˜¾ç¤ºå›¾ç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_session_statistics(session)
        if 'graph_statistics' in stats:
            graph_stats = stats['graph_statistics']
            print(f"\nğŸ“Š å›¾æ‰§è¡Œç»Ÿè®¡:")
            print(f"  èŠ‚ç‚¹æ€»æ•°: {graph_stats['total_nodes']}")
            print(f"  è¾¹æ€»æ•°: {graph_stats['total_edges']}")
            print(f"  æˆåŠŸç‡: {graph_stats['success_rate']:.2%}")
            print(f"  å¤±è´¥èŠ‚ç‚¹: {graph_stats['failed_nodes']}")
            print(f"  èŠ‚ç‚¹çŠ¶æ€åˆ†å¸ƒ: {graph_stats['node_status_distribution']}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
        print(f"\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:")
        print(session.final_answer)
        
        print("\n" + "=" * 50)
        print("âœ… æµ‹è¯•å®Œæˆ!")
        
        return session
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def test_graph_structure():
    """æµ‹è¯•å›¾ç»“æ„çš„åˆ›å»º"""
    print("\n=== æµ‹è¯•å›¾ç»“æ„åˆ›å»º ===")
    
    try:
        from core.query_decomposer import QueryPlan, SubQuery, QueryType
    except ImportError:
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç›¸å¯¹å¯¼å…¥
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from core.query_decomposer import QueryPlan, SubQuery, QueryType
    
    # åˆ›å»ºæ¨¡æ‹ŸæŸ¥è¯¢è®¡åˆ’
    query_plan = QueryPlan(
        original_query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        sub_queries=[
            SubQuery(
                id="q1", 
                query="äººå·¥æ™ºèƒ½çš„å®šä¹‰", 
                query_type=QueryType.FACTUAL,
                priority=1,
                dependencies=[],
                keywords=["äººå·¥æ™ºèƒ½", "å®šä¹‰"],
                expected_sources=["å­¦æœ¯", "ç™¾ç§‘"]
            ),
            SubQuery(
                id="q2", 
                query="äººå·¥æ™ºèƒ½çš„å†å²å‘å±•", 
                query_type=QueryType.TEMPORAL,
                priority=2,
                dependencies=["q1"],
                keywords=["äººå·¥æ™ºèƒ½", "å†å²", "å‘å±•"],
                expected_sources=["å­¦æœ¯", "å†å²"]
            ),
            SubQuery(
                id="q3", 
                query="äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸ", 
                query_type=QueryType.FACTUAL,
                priority=2,
                dependencies=["q1"],
                keywords=["äººå·¥æ™ºèƒ½", "åº”ç”¨", "é¢†åŸŸ"],
                expected_sources=["æŠ€æœ¯", "å•†ä¸š"]
            )
        ],
        execution_order=[["q1"], ["q2", "q3"]],
        estimated_time=30
    )
    
    # åˆ›å»ºæ™ºèƒ½ä½“å¹¶ç”Ÿæˆå›¾
    agent = MindSearchAgent(llm_provider=LLMProvider.SILICONFLOW)
    graph = agent._create_search_graph(query_plan)
    
    print(f"å›¾èŠ‚ç‚¹æ•°: {len(graph.nodes)}")
    print(f"å›¾è¾¹æ•°: {len(graph.edges)}")
    
    print("\nèŠ‚ç‚¹ä¿¡æ¯:")
    for node_id, node in graph.nodes.items():
        print(f"  {node.name} ({node.node_type.value}): {node.content}")
    
    print("\nè¾¹ä¿¡æ¯:")
    for edge_id, edge in graph.edges.items():
        from_node = graph.nodes[edge.from_node].name
        to_node = graph.nodes[edge.to_node].name
        print(f"  {from_node} -> {to_node}")
    
    print("\nå¯æ‰§è¡ŒèŠ‚ç‚¹:")
    ready_nodes = graph.get_ready_nodes()
    for node_id in ready_nodes:
        node = graph.nodes[node_id]
        print(f"  {node.name} ({node.node_type.value})")


if __name__ == "__main__":
    # æµ‹è¯•å›¾ç»“æ„
    test_graph_structure()
    
    # æµ‹è¯•å®Œæ•´æœç´¢æµç¨‹
    asyncio.run(test_graph_search())