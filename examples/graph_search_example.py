#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MindSearchAgent å›¾çŠ¶æ€ç®¡ç†åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¸¦æœ‰å›¾çŠ¶æ€ç®¡ç†åŠŸèƒ½çš„ MindSearchAgent è¿›è¡Œå¤æ‚æŸ¥è¯¢ã€‚
å›¾çŠ¶æ€ç®¡ç†æä¾›äº†ä»¥ä¸‹ä¼˜åŠ¿ï¼š
1. å¯è§†åŒ–æŸ¥è¯¢æ‰§è¡Œæµç¨‹
2. å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹çš„å­æŸ¥è¯¢
3. æ™ºèƒ½ä¾èµ–ç®¡ç†
4. è¯¦ç»†çš„æ‰§è¡Œç»Ÿè®¡
5. é”™è¯¯å¤„ç†å’Œæ¢å¤
"""

import asyncio
import sys
import os
from typing import Dict, Any
from datetime import datetime
import io
from contextlib import redirect_stdout



# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ä»¥ç¡®ä¿æ­£ç¡®å¯¼å…¥
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

try:
    from core.llm_manager import LLMProvider
    from agents.mindsearch_agent import MindSearchAgent
    from core.search_tools import SearchToolManager
    from core.simple_graph import NodeStatus
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„é¡¹ç›®ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


# å…¨å±€å˜é‡ç”¨äºæ”¶é›†è¾“å‡º
output_buffer = []

def log_output(message: str):
    """è®°å½•è¾“å‡ºåˆ°ç¼“å†²åŒº"""
    output_buffer.append(message)
    print(message)  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°

def print_callback(message: str, **kwargs):
    """å›è°ƒå‡½æ•°ï¼Œç”¨äºæ‰“å°æœç´¢è¿›åº¦"""
    msg = f"ğŸ“¢ {message}"
    log_output(msg)
    if kwargs:
        for key, value in kwargs.items():
            log_output(f"   {key}: {value}")


def print_graph_statistics(stats: Dict[str, Any]):
    """æ‰“å°å›¾æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
    log_output("\nğŸ“Š å›¾æ‰§è¡Œç»Ÿè®¡:")
    
    if 'graph_stats' in stats:
        graph_stats = stats['graph_stats']
        log_output(f"  æ€»èŠ‚ç‚¹æ•°: {graph_stats.get('total_nodes', 0)}")
        log_output(f"  å·²å®ŒæˆèŠ‚ç‚¹: {graph_stats.get('completed_nodes', 0)}")
        log_output(f"  å¤±è´¥èŠ‚ç‚¹: {graph_stats.get('failed_nodes', 0)}")
        log_output(f"  æˆåŠŸç‡: {graph_stats.get('success_rate', 0):.2%}")
        log_output(f"  æ‰§è¡Œæ—¶é—´: {graph_stats.get('execution_time', 0):.2f}ç§’")
        
        if 'node_details' in graph_stats:
            log_output("\n  èŠ‚ç‚¹è¯¦æƒ…:")
            for node_name, node_info in graph_stats['node_details'].items():
                status_emoji = {
                    NodeStatus.COMPLETED.value: "âœ…",
                    NodeStatus.FAILED.value: "âŒ",
                    NodeStatus.RUNNING.value: "ğŸ”„",
                    NodeStatus.PENDING.value: "â³"
                }.get(node_info.get('status', ''), "â“")
                
                log_output(f"    {status_emoji} {node_name}: {node_info.get('status', 'unknown')}")
                if node_info.get('error'):
                    log_output(f"      é”™è¯¯: {node_info['error']}")


async def example_complex_query():
    """å¤æ‚æŸ¥è¯¢ç¤ºä¾‹ï¼šäººå·¥æ™ºèƒ½ç›¸å…³çš„å¤šç»´åº¦æŸ¥è¯¢"""
    log_output("=== å¤æ‚æŸ¥è¯¢ç¤ºä¾‹ï¼šäººå·¥æ™ºèƒ½çš„å‘å±•ä¸åº”ç”¨ ===")
    
    # åˆ›å»ºæœç´¢ç®¡ç†å™¨ï¼ˆè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿé…ç½®ï¼‰
    search_manager = SearchToolManager()

    # åˆ›å»º MindSearchAgent
    agent = MindSearchAgent(
        llm_provider=LLMProvider.OPENAI,
        # search_manager=search_manager,
        max_search_steps=3,
        max_results_per_search=5
    )
    
    # å¤æ‚æŸ¥è¯¢
    query = "äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€å½“å‰åº”ç”¨é¢†åŸŸå’Œæœªæ¥è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
    
    log_output(f"ğŸ” æŸ¥è¯¢: {query}\n")
    
    try:
        # æ‰§è¡Œæœç´¢ï¼ˆä½¿ç”¨å›¾çŠ¶æ€ç®¡ç†ï¼‰
        result = await agent.asearch(
            query=query,
            callback=print_callback
        )
        
        log_output("\n" + "="*50)
        log_output("ğŸ¯ æœç´¢ç»“æœ:")
        log_output(result)
        
        # è·å–å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_session_statistics(session=result)
        print_graph_statistics(stats)
        
    except Exception as e:
        log_output(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        
        # å³ä½¿å‡ºé”™ä¹Ÿæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_session_statistics(session=result)
        print_graph_statistics(stats)


async def example_simple_query():
    """ç®€å•æŸ¥è¯¢ç¤ºä¾‹"""
    log_output("\n=== ç®€å•æŸ¥è¯¢ç¤ºä¾‹ï¼šPythonç¼–ç¨‹ ===")
    
    # search_manager = SearchManager()
    search_manager = SearchToolManager()
    agent = MindSearchAgent(
        llm_provider=LLMProvider.SILICONFLOW,
        max_search_steps=3,
        max_results_per_search=5
    )
    
    query = "Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹å’Œä¼˜åŠ¿"
    log_output(f"ğŸ” æŸ¥è¯¢: {query}\n")
    
    try:
        result = await agent.asearch(
            query=query,
            callback_func=print_callback
        )
        
        log_output("\n" + "="*50)
        log_output("ğŸ¯ æœç´¢ç»“æœ:")
        log_output(result)
        
        stats = agent.get_session_statistics(session=result)
        print_graph_statistics(stats)
        
    except Exception as e:
        log_output(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


async def example_graph_visualization():
    """å›¾å¯è§†åŒ–ç¤ºä¾‹"""
    log_output("\n=== å›¾å¯è§†åŒ–ç¤ºä¾‹ ===")
    
    # search_manager = SearchManager()
    search_manager = SearchToolManager()
    agent = MindSearchAgent(
        llm_provider=LLMProvider.OPENAI,
        # search_manager=search_manager,
        max_search_steps=3,
        max_results_per_search=5
    )
    
    query = "æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€ç®—æ³•åˆ†ç±»å’Œå®é™…åº”ç”¨"
    log_output(f"ğŸ” æŸ¥è¯¢: {query}\n")
    
    # å®šä¹‰è¯¦ç»†çš„å›è°ƒå‡½æ•°
    def detailed_callback(message: str, **kwargs):
        log_output(f"ğŸ“¢ {message}")
        
        # å¦‚æœæœ‰å›¾ç›¸å…³ä¿¡æ¯ï¼Œæ˜¾ç¤ºå›¾çŠ¶æ€
        if 'graph' in kwargs:
            graph = kwargs['graph']
            ready_nodes = graph.get_ready_nodes()
            if ready_nodes:
                node_names = [graph.nodes[nid].name for nid in ready_nodes]
                log_output(f"   å¯æ‰§è¡ŒèŠ‚ç‚¹: {', '.join(node_names)}")
        
        # æ˜¾ç¤ºå…¶ä»–ä¿¡æ¯
        for key, value in kwargs.items():
            if key != 'graph':  # é¿å…æ‰“å°æ•´ä¸ªå›¾å¯¹è±¡
                log_output(f"   {key}: {value}")
    
    try:
        result = await agent.asearch(
            query=query,
            callback=detailed_callback
        )
        
        log_output("\n" + "="*50)
        log_output("ğŸ¯ æœç´¢ç»“æœ:")
        log_output(result)
        
        # è·å–å›¾ç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_session_statistics(session=result)
        print_graph_statistics(stats)
        
        # æ˜¾ç¤ºå›¾ç»“æ„ä¿¡æ¯
        if hasattr(agent, '_current_graph') and agent._current_graph:
            graph = agent._current_graph
            log_output("\nğŸ”— å›¾ç»“æ„æ¦‚è§ˆ:")
            log_output(f"  èŠ‚ç‚¹æ€»æ•°: {len(graph.nodes)}")
            log_output(f"  è¾¹æ€»æ•°: {len(graph.edges)}")
            
            # æŒ‰ç±»å‹ç»Ÿè®¡èŠ‚ç‚¹
            from collections import defaultdict
            node_types = defaultdict(int)
            for node in graph.nodes.values():
                node_types[node.node_type.value] += 1
            
            log_output("  èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ:")
            for node_type, count in node_types.items():
                log_output(f"    {node_type}: {count}")
        
    except Exception as e:
        log_output(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


def print_usage_guide():
    """æ‰“å°ä½¿ç”¨æŒ‡å—"""
    log_output("\n" + "="*60)
    log_output("ğŸ“– MindSearchAgent å›¾åŠŸèƒ½ä½¿ç”¨æŒ‡å—")
    log_output("="*60)
    log_output("""
ğŸ”§ ä¸»è¦åŠŸèƒ½:
  1. è‡ªåŠ¨æŸ¥è¯¢åˆ†è§£ - å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­æŸ¥è¯¢
  2. å›¾çŠ¶æ€ç®¡ç† - ä½¿ç”¨æœ‰å‘æ— ç¯å›¾ç®¡ç†æŸ¥è¯¢æ‰§è¡Œæµç¨‹
  3. å¹¶è¡Œæ‰§è¡Œ - ç‹¬ç«‹çš„å­æŸ¥è¯¢å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
  4. ä¾èµ–ç®¡ç† - è‡ªåŠ¨å¤„ç†å­æŸ¥è¯¢ä¹‹é—´çš„ä¾èµ–å…³ç³»
  5. é”™è¯¯å¤„ç† - æ™ºèƒ½å¤„ç†èŠ‚ç‚¹å¤±è´¥å’Œä¾èµ–é”™è¯¯
  6. æ‰§è¡Œç»Ÿè®¡ - æä¾›è¯¦ç»†çš„æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½åˆ†æ

ğŸš€ ä½¿ç”¨æ­¥éª¤:
  1. åˆ›å»º SearchManager å®ä¾‹
  2. åˆ›å»º MindSearchAgent å®ä¾‹
  3. è°ƒç”¨ asearch() æ–¹æ³•æ‰§è¡ŒæŸ¥è¯¢
  4. ä½¿ç”¨ callback å‚æ•°ç›‘æ§æ‰§è¡Œè¿›åº¦
  5. é€šè¿‡ get_session_statistics() è·å–ç»Ÿè®¡ä¿¡æ¯

ğŸ’¡ æœ€ä½³å®è·µ:
  - ä¸ºå¤æ‚æŸ¥è¯¢è®¾ç½®åˆé€‚çš„ max_sub_queries å‚æ•°
  - ä½¿ç”¨å›è°ƒå‡½æ•°ç›‘æ§é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
  - å®šæœŸæ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯ä»¥ä¼˜åŒ–æŸ¥è¯¢ç­–ç•¥
  - å¤„ç†å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ

ğŸ“Š å›¾çŠ¶æ€ç®¡ç†ä¼˜åŠ¿:
  - å¯è§†åŒ–æŸ¥è¯¢æ‰§è¡Œæµç¨‹
  - æé«˜æŸ¥è¯¢æ‰§è¡Œæ•ˆç‡
  - æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œæ¢å¤
  - è¯¦ç»†çš„æ€§èƒ½åˆ†æ
""")


def save_output_to_markdown():
    """å°†è¾“å‡ºä¿å­˜åˆ°markdownæ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"graph_search_example_output_{timestamp}.md"
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("# MindSearchAgent å›¾çŠ¶æ€ç®¡ç†åŠŸèƒ½æ¼”ç¤ºè¾“å‡º\n\n")
        f.write(f"**æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        for item in output_buffer:
            # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if isinstance(item, str):
                line = item
            else:
                line = str(item)
            
            # å¤„ç†markdownç‰¹æ®Šå­—ç¬¦
            line = line.replace('\n', '\n\n')
            f.write(line + '\n\n')
    
    log_output(f"\nğŸ“„ è¾“å‡ºå·²ä¿å­˜åˆ°æ–‡ä»¶: {filename}")
    return filename


async def main():
    """ä¸»å‡½æ•°"""
    log_output("ğŸš€ MindSearchAgent å›¾çŠ¶æ€ç®¡ç†åŠŸèƒ½æ¼”ç¤º")
    log_output("="*50)
    
    # æ‰“å°ä½¿ç”¨æŒ‡å—
    print_usage_guide()
    
    # è¿è¡Œç¤ºä¾‹
    # await example_complex_query()
    await example_simple_query()
    # await example_graph_visualization()
    
    log_output("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
    log_output("\nğŸ’¡ æç¤º: åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¯·ç¡®ä¿æ­£ç¡®é…ç½®æœç´¢å¼•æ“å’ŒAPIå¯†é’¥ã€‚")
    
    # ä¿å­˜è¾“å‡ºåˆ°markdownæ–‡ä»¶
    filename = save_output_to_markdown()
    print(f"\nâœ… å®Œæ•´çš„æ‰§è¡Œè¿‡ç¨‹å·²ä¿å­˜åˆ°: {filename}")


if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())